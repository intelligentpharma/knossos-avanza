# This is the main configuration file for the application.
# ~~~~~
application.name=HerculesBackEnd

# Application mode
# ~~~~~
# Set to dev to enable instant reloading and other development help.
# Otherwise set to prod.
application.mode=dev
%research.application.mode=prod
%preprod.application.mode=prod
%prod.application.mode=prod

# Http params
# ~~~~~
http.maxParams=2000

# Secret key
# ~~~~~
# The secret key is used to secure cryptographics functions
# If you deploy your application to several instances be sure to use the same key !
application.secret=pnWAqiH9iS7CRvJya8APE0MvgHkklg8Bx9Xsg8kM0TEQSqA2IV6icXjujcxL27w9

# i18n
# ~~~~~
# Define locales used by your application.
# You can then place localized messages in conf/messages.{locale} files
# application.langs=fr,en,ja

# Date format
# ~~~~~
date.format=yyyy-MM-dd
# date.format.fr=dd/MM/yyyy

# Server configuration
# ~~~~~
# If you need to change the HTTP port, uncomment this (default is set to 9000)
%prod.http.port=60112
http.port=61112
%test.http.port=62112
%research.http.port=63112
#%prod.http.port=60443
#http.port=61443
#%test.http.port=62443
#%research.http.port=63443

# HTTPS config
# ~~~~~
#https.port=60443
## just guessing here
#%preprod.https.port=61443
#https.port=60112
# just guessing here
#%preprod.https.port=61112
#certificate.key.file=/etc/pki/knossos/preprod/private/ca.key
#certificate.file=/etc/pki/knossos/preprod/certs/ca.crt
#certificate.key.file=conf/host.key
#certificate.file=conf/host.cert


#
# By default the server listen for HTTP on the wilcard address.
# You can restrict this.
# http.address=127.0.0.1

# Session configuration
# ~~~~~~~~~~~~~~~~~~~~~~
# By default, session will be written to the transient PLAY_SESSION cookie.
# The cookies are not secured by default, only set it to true
# if you're serving your pages through https.
# application.session.cookie=PLAY
# application.session.maxAge=1h
# application.session.secure=false

# Session/Cookie sharing between subdomain
# ~~~~~~~~~~~~~~~~~~~~~~
# By default a cookie is only valid for a specific domain. By setting
# application.defaultCookieDomain to '.example.com', the cookies
# will be valid for all domains ending with '.example.com', ie:
# foo.example.com and bar.example.com
# application.defaultCookieDomain=.example.com

# JVM configuration
# ~~~~~
# Define which port is used by JPDA when application is in debug mode (default is set to 8000)
jpda.port=8001
%test.jpda.port=8002
#
# Java source level => 1.5, 1.6 or 1.7 (experimental)
# java.source=1.5
jvm.memory=-Xmx1024M -Xms512M -verbose:gc
%prod.jvm.memory=-Xmx4096M -Xms256M -Xss256k -verbose:gc
%preprod.jvm.memory=-Xmx4096M -Xms256M -Xss256k -verbose:gc

# Log level
# ~~~~~
# Specify log level for your application.
# If you want a very customized log, create a log4j.properties file in the conf directory
application.log=DEBUG
%prod.application.log=INFO
#
# More logging configuration
# application.log.path=log4j.properties
# application.log.system.out=off

# Database configuration
# ~~~~~ 
# Enable a database engine if needed.
#
# To quickly set up a development database, use either:
#   - mem : for a transient in memory database (H2 in memory)
#   - fs  : for a simple file written database (H2 file stored)
%test.db=mem
#%dev.db=fs
#%dev.db.driver=org.h2.Driver 
#%dev.db.user=sa
#%dev.db.pass=
#
# To connect to a local MySQL5 database, use:
# db=mysql:user:pwd@database_name
#

### TODO: database_id and db.url are using the same database id
# If you need a full JDBC configuration use the following :
%dev.database_id=knossos1
%dev.db.url=jdbc:postgresql:knossos1
%dev.db.driver=org.postgresql.Driver
%dev.db.user=postgres
%dev.db.pass=

%dev_avanza.database_id=knossos1
%dev_avanza.db.url=jdbc:postgresql:knossos1
%dev_avanza.db.driver=org.postgresql.Driver
%dev_avanza.db.user=postgres
%dev_avanza.db.pass=

%preprod.database_id=knossos_preprod
%preprod.db.url=jdbc:postgresql://hidra-11/knossos_preprod
%preprod.db.driver=org.postgresql.Driver
%preprod.db.user=knossos_admin
%preprod.db.pass=knossosADMIN2011

%prod.database_id=knossos_prod
%prod.db.url=jdbc:postgresql://hidra-11/knossos_prod
%prod.db.driver=org.postgresql.Driver
%prod.db.user=knossos_admin
%prod.db.pass=knossosADMIN2011

%research.db.url=jdbc:postgresql:knossos_research
%research.db.driver=org.postgresql.Driver
%research.db.user=knossos_admin
%research.db.pass=knossosADMIN2011


#
# Connections pool configuration :
# db.pool.timeout=1000
# db.pool.maxSize=30
# db.pool.minSize=10
%preprod.db.pool.maxSize=200
%prod.db.pool.maxSize=200
%research.db.pool.maxSize=200
db.pool.maxSize=100
db.pool.timeout=10000

#
# If you want to reuse an existing Datasource from your application server, use:
# db=java:/comp/env/jdbc/myDatasource
#
# When using an existing Datasource, it's sometimes needed to destroy it when
# the application is stopped. Depending on the datasource, you can define a
# generic "destroy" method :
# db.destroyMethod=close

# JPA Configuration (Hibernate)
# ~~~~~
#
# Specify the custom JPA dialect to use here (default to guess):
# jpa.dialect=org.hibernate.dialect.PostgreSQLDialect
#
# Specify the ddl generation pattern to use. Set to none to disable it 
# (default to update in DEV mode, and none in PROD mode):
# jpa.ddl=update
#
# Debug SQL statements (logged using DEBUG level):
%dev.jpa.debugSQL=false
%test.jpa.debugSQL=false
#
# You can even specify additional hibernate properties here:
# hibernate.use_sql_comments=true
# hibernate.show_sql=true
# hibernate.format_sql=true
# ...
#
# Store path for Blob content
attachments.path=data/attachments
%dev.database.files.storage.path=../../data
%dev_avanza.database.files.storage.path=../../data
%prod.database.files.storage.path=<knossos_home>/data
%preprod.database.files.storage.path=<knossos_home>/data
%research.database.files.storage.path=<knossos_home>/data
database.files.storage.path=data

%dev_avanza.database.files.storage.alternative_path=<knossos_home>/data

# Memcached configuration
# ~~~~~ 
# Enable memcached if needed. Otherwise a local cache is used.
# memcached=enabled
#
# Specify memcached host (default to 127.0.0.1:11211)
# memcached.host=127.0.0.1:11211
#
# Or you can specify multiple host to build a distributed cache
# memcached.1.host=127.0.0.1:11211
# memcached.2.host=127.0.0.1:11212

# HTTP Response headers control for static files
# ~~~~~
# Set the default max-age, telling the user's browser how long it should cache the page.
# Default is 3600 (one hour). Set it to 0 to send no-cache.
# This is only read in prod mode, in dev mode the cache is disabled.
# http.cacheControl=3600

# If enabled, Play will generate entity tags automatically and send a 304 when needed.
# Default is true, set it to false to deactivate use of entity tags.
# http.useETag=true

# Custom mime types
# mimetype.xpi=application/x-xpinstall

# WS configuration
# ~~~~~
# Default engine is Async Http Client, uncomment to use
# the JDK's internal implementation
# webservice = urlfetch
# If you need to set proxy params for WS requests
# http.proxyHost = localhost
# http.proxyPort = 3128
# http.proxyUser = jojo
# http.proxyPassword = jojo

# Mail configuration
# ~~~~~ 
# Default is to use a mock Mailer
mail.smtp=mock

# Or, specify mail host configuration
# mail.smtp.host=127.0.0.1
# mail.smtp.user=admin
# mail.smtp.pass=
# mail.smtp.channel=ssl

# Url-resolving in Jobs
# ~~~~~~
# When rendering templates with reverse-url-resoling (@@{..}) in Jobs (which do not have an inbound Http.Request),
# ie if sending a HtmlMail, Play need to know which url your users use when accessing your app.
# %test.application.baseUrl=http://localhost:9000/
# %prod.application.baseUrl=http://www.yourdomain.com/

# Jobs executor
# ~~~~~~
# Size of the Jobs pool
play.jobs.pool=66

# These are executed in SLURM
knossos.default.slurm.jobs.pool=2
%prod.knossos.default.slurm.jobs.pool=43
%preprod.knossos.default.slurm.jobs.pool=5
%research.knossos.default.slurm.jobs.pool=5

# These are executed in the master node
knossos.priority.jobs.pool=1
%prod.knossos.priority.jobs.pool=2

# Execution pool
# ~~~~~
# Default to 1 thread in DEV mode or (nb processors + 1) threads in PROD mode.
# Try to keep a low as possible. 1 thread will serialize all requests (very useful for debugging purpose)
# play.pool=3

# Open file from errors pages
# ~~~~~
# If your text editor supports opening files by URL, Play! will
# dynamically link error pages to files 
#
# Example, for textmate:
# play.editor=txmt://open?url=file://%s&line=%s

# Testing. Set up a custom configuration for test mode
# ~~~~~
#%test.module.cobertura=${play.path}/modules/cobertura
%test.application.mode=dev
%test.db.url=jdbc:h2:mem:play;MODE=MYSQL;LOCK_MODE=0
%test.jpa.ddl=create
%test.mail.smtp=mock

# Import the secure module
# module.secure=${play.path}/modules/secure

# Molecule paths. Set up the paths where the molecule files are stored.
# ~~~~~
molecules.dlgs.home=/mnt/hidra-00/icarus/$user/dlgs
molecules.database.home=/mnt/hidra-00/icarus/$user/databases
molecules.referenceMolecule.home=/mnt/hidra-00/icarus/$user/ligands

# Engine configuration parameters
# ~~~~~

time.waiting.between.db.retrieval.attempts=2000
%test.time.waiting.between.db.retrieval.attempts=10
max.retries.database=1000
%test.max.retries.database=1

pythonsh=pythonsh
%research.pythonsh=/grid/apps/MGLTools/bin/pythonsh
%preprod.pythonsh=/grid/apps/MGLTools/bin/pythonsh
%prod.pythonsh=/grid/apps/MGLTools/bin/pythonsh
%dev_avanza.pythonsh=/grid/apps/MGLTools/bin/pythonsh
%dev_avanza.ssh=ssh root@hidra-01

opt_dir=.
%research.opt_dir=/opt/ip/research/knossos/BackEnd
%preprod.opt_dir=/opt/ip/preprod/knossos/BackEnd
%prod.opt_dir=/opt/ip/production/knossos/BackEnd
%dev_avanza.opt_dir=ssh root@hidra-01 /opt/ip/production/knossos/BackEnd

knossos_home=.
%research.knossos_home=/grid/env/research
%preprod.knossos_home=/grid/env/preprod
%prod.knossos_home=/grid/env/production
%dev_avanza.knossos_home=/grid/env/dev_avanza

tmp.dir=<knossos_home>/tmp
%dev_avanza.tmp.dir=<knossos_home>/workspace/knossos
%prod.tmp.dir=<knossos_home>/workspace/knossos
%preprod.tmp.dir=<knossos_home>/workspace/knossos
%research.tmp.dir=<knossos_home>/workspace/knossos
scripts_home=<knossos_home>/scripts
bin_home=<knossos_home>/ext/bin
logs_dir=<opt_dir>/logs
%dev_avanza.logs_dir=logs

vina=<bin_home>/vina --out %s --receptor %s --ligand %s --center_x %.3f --center_y %.3f --center_z %.3f --size_x %.3f --size_y %.3f --size_z %.3f --exhaustiveness %d --cpu 1 %s
score_vina=<bin_home>/vina --receptor %s --ligand %s --center_x %.3f --center_y %.3f --center_z %.3f --size_x %.3f --size_y %.3f --size_z %.3f --cpu 1 --score_only
vina_inverse=<bin_home>/vina_inverse --out %s --receptor %s --ligand %s --center_x %.3f --center_y %.3f --center_z %.3f --size_x %.3f --size_y %.3f --size_z %.3f --exhaustiveness %d --cpu 1 %s
vina_inverse_4_03=<bin_home>/vina_inverse_4_03 --out %s --receptor %s --ligand %s --center_x %.3f --center_y %.3f --center_z %.3f --size_x %.3f --size_y %.3f --size_z %.3f --exhaustiveness %d --cpu 1 %s
vina_inverse_4_08=<bin_home>/vina_inverse_4_08 --out %s --receptor %s --ligand %s --center_x %.3f --center_y %.3f --center_z %.3f --size_x %.3f --size_y %.3f --size_z %.3f --exhaustiveness %d --cpu 1 %s
vina_inverse_4_14=<bin_home>/vina_inverse_4_14 --out %s --receptor %s --ligand %s --center_x %.3f --center_y %.3f --center_z %.3f --size_x %.3f --size_y %.3f --size_z %.3f --exhaustiveness %d --cpu 1 %s
vina_inverse_7_03=<bin_home>/vina_inverse_7_03 --out %s --receptor %s --ligand %s --center_x %.3f --center_y %.3f --center_z %.3f --size_x %.3f --size_y %.3f --size_z %.3f --exhaustiveness %d --cpu 1 %s
vina_inverse_7_08=<bin_home>/vina_inverse_7_08 --out %s --receptor %s --ligand %s --center_x %.3f --center_y %.3f --center_z %.3f --size_x %.3f --size_y %.3f --size_z %.3f --exhaustiveness %d --cpu 1 %s
vina_inverse_7_14=<bin_home>/vina_inverse_7_14 --out %s --receptor %s --ligand %s --center_x %.3f --center_y %.3f --center_z %.3f --size_x %.3f --size_y %.3f --size_z %.3f --exhaustiveness %d --cpu 1 %s
vina_inverse_10_03=<bin_home>/vina_inverse_10_03 --out %s --receptor %s --ligand %s --center_x %.3f --center_y %.3f --center_z %.3f --size_x %.3f --size_y %.3f --size_z %.3f --exhaustiveness %d --cpu 1 %s
vina_inverse_10_08=<bin_home>/vina_inverse_10_08 --out %s --receptor %s --ligand %s --center_x %.3f --center_y %.3f --center_z %.3f --size_x %.3f --size_y %.3f --size_z %.3f --exhaustiveness %d --cpu 1 %s
vina_inverse_10_14=<bin_home>/vina_inverse_10_14 --out %s --receptor %s --ligand %s --center_x %.3f --center_y %.3f --center_z %.3f --size_x %.3f --size_y %.3f --size_z %.3f --exhaustiveness %d --cpu 1 %s
pdbqt_split=<scripts_home>/pdbqt_split.pl %s
%dev_avanza.compress_maps=<ssh> <pythonsh> <bin_home>/copy_files.py %s
compress_maps=<pythonsh> <bin_home>/copy_files.py %s
AD4=<pythonsh> <bin_home>/autodock_local.py 4
AD42=<pythonsh> <bin_home>/autodock_local.py 4.2
autogrid4=<bin_home>/autogrid4
autogrid4_amanda=<bin_home>/autogrid4_amanda
autogrid.inverseAD=<bin_home>/autogrid4_inverseAD
autogrid42=<bin_home>/autogrid4.2
RealEA=<bin_home>/RealEA
autogrid.nod_noph=<bin_home>/autogrid4_inverseAD_nod_noph
autogrid.nod=<bin_home>/autogrid4_inverseAD_nod
corina=<bin_home>/corina -i t=smiles -o t=sdf -d rs,neu,rc,mc=10,de=10,flapn,sc,stergen,msc=8,msi=300,preserve,names,wh,r2d %s %s
complete.corina=<bin_home>/corina -i t=sdf -o t=sdf,lname -d rs,neu,rc,mc=%s,de=%s,flapn,sc,stergen,msc=%s,msi=%s,preserve,names,wh,r2d %s %s
single.corina=<bin_home>/corina -i t=smiles -o t=sdf -d wh %s %s
tanimoto=<bin_home>/tanimoto %s %s %s %d

%dev.dbhost=localhost
%dev_avanza.dbhost=localhost
%preprod.dbhost=hidra-11
%prod.dbhost=hidra-11

%dev.nclust=2
%dev_avanza.nclust=8
%preprod.nclust=8
%prod.nclust=8

%dev.svmNclust=1
%dev_avanza.svmNclus=8
%preprod.svmNclust=8
%prod.svmNclust=8

qsar.pca=<R> -f <scripts_home>/qsarPCA.R --args <scripts_home> %s
qsar.pls=<R> -f <scripts_home>/qsarPls.R --args <scripts_home> %s
qsar.sparsePls=<R> -f <scripts_home>/qsarSparsePls.R --args <scripts_home> %s <database_id> <dbhost>
qsar.preparation=<R> -f <scripts_home>/qsarPreparation.R --args <scripts_home> %s <database_id> <dbhost>
qsar.plsIteration = <R> -f <scripts_home>/qsarPlsValidationIteration.R --args <scripts_home> %s <database_id> <dbhost>
qsar.plsModelSelection = <R> -f <scripts_home>/qsarPlsModelSelection.R --args <scripts_home> %s <database_id> <dbhost>
qsar.plsRefresh = <R> -f <scripts_home>/qsarPlsRefresh.R --args <scripts_home> %s <database_id> <dbhost>
qsar.svmRegression=<R> -f <scripts_home>/qsarSvmRegression.R --args <scripts_home> %s
qsar.svmRegressionIteration = <R> -f <scripts_home>/qsarSvmRegressionValidationIteration.R --args <scripts_home> %s <database_id> <dbhost> <svmNclust>
qsar.svmRegressionModelSelection = <R> -f <scripts_home>/qsarSvmRegressionModelSelection.R --args <scripts_home> %s <database_id> <dbhost>
qsar.svmRegressionRefresh = <R> -f <scripts_home>/qsarSvmRegressionRefresh.R --args <scripts_home> %s <database_id> <dbhost>
qsar.svmClassification=<R> -f <scripts_home>/qsarSvmClassification.R --args <scripts_home> %s <database_id> <dbhost> <svmNclust>
qsar.svmClassificationRefresh = <R> -f <scripts_home>/qsarSvmClassificatonRefresh.R --args <scripts_home> %s <database_id> <dbhost>
descriptors.calculator=<R> -f <scripts_home>/descriptorsCalculator.R --args <scripts_home> %s <nclust>
prediction.qsar=<R> -f <scripts_home>/qsarPredictionParallel.R --args <scripts_home> %s <database_id> <dbhost> <nclust>
qsarPreprocess.pls=<R> -f <scripts_home>/databasePreProcess.R --args %s %s %s %s %s %s %s
clusterize=<R> -f <scripts_home>/lingoClusterization.R --args <scripts_home> %s
correlationMatrix=<R> -f <scripts_home>/correlationMatrix.R --args <scripts_home> %s
fingerprintSimilarity = <R> -f <scripts_home>/fingerprintPegasus.R --args <scripts_home> %s %s %s %s
plsPholus=<R> -f <scripts_home>/plsPholus.R --args <scripts_home> %s %s
eaPholus=<R> -f <scripts_home>/eaPholus.R --args <scripts_home> %s %s %s
multiStatistics=<R> -f <scripts_home>/ExperimentsValidation.R --args <scripts_home> %s %s
performanceMetrics=<R> -f <scripts_home>/performanceMetricsPlotter.R --args <scripts_home> %s
moleculeDatabaseBoxPlot=<R> -f <scripts_home>/moleculeDBBoxPlot.R --args <scripts_home> %s %s %s %s
diversity.selection = <Rscript> <scripts_home>/diversitySelection.R -c <scripts_home> -i %s -n %s -h %s -s %s -m %s -d %s -a %s -b %s -l %s -p %s 

prepareReceptor=<pythonsh> <scripts_home>/prepare_receptor4.py -r %s -A none -o %s
%dev_avanza.prepareReceptor=<ssh> <pythonsh> <scripts_home>/prepare_receptor4.py -r %s -A none -o %s

prepareLigand=<pythonsh> <scripts_home>/prepare_ligand4.py -l %s -o %s
%dev_avanza.prepareLigand=<ssh> <pythonsh> <scripts_home>/prepare_ligand4.py -l %s -o %s
pdbbox=awk -f <scripts_home>/pdbbox_fixed_offset.awk add=%s %s
pdbbox_grinds=awk -f <scripts_home>/pdbbox_fixed_offset.awk add=%s passo=%s %s

%dev_avanza.pdbbox=ssh knossos@hidra-01 awk -f <scripts_home>/pdbbox_fixed_offset.awk add=%s %s
%dev_avanza.pdbbox_grinds=ssh knossos@hidra-01 awk -f <scripts_home>/pdbbox_fixed_offset.awk add=%s passo=%s %s

torsdof=grep TORSDOF %s
dlgToPdbqtConverter=<scripts_home>/dlgToPdbqt.pl %s %s
dlgInfo=<scripts_home>/dlgInfo.pl %s
dlgToClusteredPdbqtConverter=<scripts_home>/dlgToClusteredPdbqt.pl %s %s
corina_fix=<scripts_home>/corina_smi2sdf_adjust.pl %s %s
map2xyz=<scripts_home>/map2xyz.pl %s %s %s

%dev_avanza.torsdof=ssh knossos@hidra-01 grep TORSDOF %s
%dev_avanza.dlgToPdbqtConverter=ssh knossos@hidra-01 <scripts_home>/dlgToPdbqt.pl %s %s
%dev_avanza.dlgToClusteredPdbqtConverter=ssh knossos@hidra-01 <scripts_home>/dlgToClusteredPdbqt.pl %s %s
%dev_avanza.dlgInfo=ssh knossos@hidra-01 <scripts_home>/dlgInfo.pl %s

#In order to calculate GRINDS, vmd version must be 1.8.6
vmdCommand = vmd %s -dispdev text -e %s
vmdScript = <scripts_home>/vmd_cmd

grindPointCalculatorJar = java -cp <bin_home>/GrindPointsCalculator.jar grindpointscalculator.GrindPointsCalculator %s %s %s %s %s %s %s %s %s %s
grindVectorCalculatorJar = java -cp <bin_home>/GrindPointsCalculator.jar grindvectorcalculator.GrindVectorCalculator %s %s %s %s %s %s %s %s %s %s %s %s %s %s %s %s

%dev_avanza.srun=ssh root@hidra-01 /usr/local/bin/srun
srun= /usr/local/bin/srun
#srun=/grid/apps/scripts/hrun
obprop=/usr/local/bin/obprop
babel=/usr/local/bin/obabel -i%s %s %s -o%s -O%s
%dev_avanza.babel=ssh knossos@hidra-01 /usr/local/bin/obabel -i%s %s %s -o%s -O%s

R=/usr/local/bin/R --vanilla --slave
%dev_avanza.R=ssh root@hidra-01 /usr/local/bin/R-pre --vanilla --slave
%dev.R=/usr/local/bin/R --vanilla --slave
%preprod.R=/usr/local/bin/R-pre --vanilla --slave
%prod.R=/usr/local/bin/R-prod --vanilla --slave

Rscript = Rscript
%dev_avanza.Rscript=ssh root@hidra-01 /usr/local/bin/Rscript-prod
%dev.Rscript=Rscript
%preprod.Rscript=/usr/local/bin/Rscript-pre
%prod.Rscript=/usr/local/bin/Rscript-prod

%dev.selene_num_evals=500000
selene_num_evals=5000000
inverseAD_num_evals=2500000

#%research.metrics=/usr/bin/time -a -o <logs_dir>/jobs/metrics -f \`hostname\`-[%C]-[T:%es]_[CPU:%P]_[MEM:%MKb]_[PF:%F]_[CSW:%w]_[I:%I]_[O:%O]
#%prod.metrics=/usr/bin/time -a -o <logs_dir>/jobs/metrics -f \`hostname\`-[%C]-[T:%es]_[CPU:%P]_[MEM:%MKb]_[PF:%F]_[CSW:%w]_[I:%I]_[O:%O]
#%preprod.metrics=/usr/bin/time -a -o <logs_dir>/jobs/metrics -f \`hostname\`-[%C]-[T:%es]_[CPU:%P]_[MEM:%MKb]_[PF:%F]_[CSW:%w]_[I:%I]_[O:%O]
metrics=

tail=tail -1000

#
# SCHRODINGER 
# ~~~~~
schrodinger_dir=/home/soft/schrodinger
%dev_avanza.schrodinger_dir=ssh root@hidra-01 /grid/apps/schrodinger
%preprod.schrodinger_dir=/grid/apps/schrodinger
%prod.schrodinger_dir=/grid/apps/schrodinger

sdconvert=<schrodinger_dir>/utilities/sdconvert -i%s %s -o%s %s
epik=<schrodinger_dir>/epik -ph %s -pht %s -i%s %s -o%s %s -WAIT
applyhtreat=<schrodinger_dir>/utilities/applyhtreat %s %s


schrodinger_ph4=<schrodinger_dir>/phase_find_matches %s %s %s -match 2 -nosort -ex -osd -WAIT -NOCHECKPOINT

avanza_scripts_dir=/root/avanza

%dev_avanza.create_slurm_queue_with_workers=ssh root@hidra-01 <avanza_scripts_dir>/crear_cola_hidra.sh -ip %s -name %s -queue %s
%prod.create_slurm_queue_with_workers=sudo <avanza_scripts_dir>/crear_cola_hidra.sh -ip %s -name %s -queue %s
%preprod.create_slurm_queue_with_workers=sudo <avanza_scripts_dir>/crear_cola_hidra.sh -ip %s -name %s -queue %s

%dev_avanza.remove_hidra_queue=ssh root@hidra-01 <avanza_scripts_dir>/borrar_cola_hidra.sh -queue %s -names %s
%prod.remove_hidra_queue=sudo <avanza_scripts_dir>/borrar_cola_hidra.sh -queue %s -names %s
%preprod.remove_hidra_queue=sudo <avanza_scripts_dir>/borrar_cola_hidra.sh -queue %s -names %s

%dev_avanza.sinfo=ssh root@hidra-01 sinfo
%prod.sinfo=/usr/local/bin/sinfo
%preprod.sinfo=/usr/local/bin/sinfo

%dev_avanza.undrain=ssh root@hidra-01 scontrol update nodename=%s state=resume
%prod.undrain=/usr/local/bin/scontrol update nodename=%s state=resume
%preprod.undrain=/usr/local/bin/scontrol update nodename=%s state=resume

%dev_avanza.check_connection=ssh -t root@hidra-01 ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -i <scripts_home>/avanza.pem root@%s true
%prod.check_connection=ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -i <scripts_home>/avanza.pem root@%s true
%preprod.check_connection=ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -i <scripts_home>/avanza.pem root@%s true

%dev_avanza.launch_vpn=ssh root@hidra-01 <avanza_scripts_dir>/conectar_vpn.sh
%prod.launch_vpn=sudo <avanza_scripts_dir>/conectar_vpn.sh
%preprod.launch_vpn=sudo <avanza_scripts_dir>/conectar_vpn.sh

%dev_avanza.stop_vpn=ssh root@hidra-01 <avanza_scripts_dir>/desconectar_vpn.sh
%prod.stop_vpn=sudo <avanza_scripts_dir>/desconectar_vpn.sh
%preprod.stop_vpn=sudo <avanza_scripts_dir>/desconectar_vpn.sh

%dev_avanza.gcloud_userData=scripts/userData_gcloud.sh
%prod.gcloud_userData=<scripts_home>/userData_gcloud.sh
%preprod.gcloud_userData=<scripts_home>/userData_gcloud.sh

#Pythia Knossos
pythia_home=<knossos_home>/pythiaEmbedded
pythiaKnossos=java -Xms512m -Xmx3072m -cp ./lib/junit.jar:./lib/org.hamcrest.core_1.1.0.v20090501071000.jar:./lib/file-utils-1.0.jar:./lib/junit-addons-1.4.jar -jar <pythia_home>/pythia.jar -i %s -st %s -at %s -s %s -db %s -ip 100.0 -o %s
